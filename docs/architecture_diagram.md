# System Architecture Diagram

## Week 4 - Real-Time Crypto AI Service Architecture

### High-Level System Overview

```mermaid
flowchart TB
    subgraph External["External Data Source"]
        CB[("ğŸŒ Coinbase\nWebSocket API")]
    end
    
    subgraph Ingestion["Ingestion Layer"]
        WS["ğŸ“¡ WebSocket Ingestor\n(ws_ingest.py)"]
        REPLAY["ğŸ”„ Replay Script\n(replay_to_kafka.py)"]
    end
    
    subgraph Messaging["Message Broker"]
        KAFKA[("ğŸ“¨ Kafka\n(KRaft Mode)\nPort: 9092")]
        TOPIC1["ticks.raw"]
        TOPIC2["ticks.features"]
    end
    
    subgraph Processing["Feature Engineering"]
        FE["âš™ï¸ Feature Pipeline\n(featurizer.py)"]
    end
    
    subgraph API["Prediction API"]
        FAST["ğŸš€ FastAPI\nPort: 8000"]
        MODEL["ğŸ¤– ML Model\n(Random Forest)"]
        BASE["ğŸ“Š Baseline\n(Z-Score)"]
    end
    
    subgraph Monitoring["Monitoring & Tracking"]
        MLFLOW["ğŸ“ˆ MLflow\nPort: 5001"]
        PROM["ğŸ“Š Prometheus\nPort: 9090"]
        GRAF["ğŸ“‰ Grafana\nPort: 3000"]
    end
    
    CB -->|"Live Stream"| WS
    WS -->|"Publish"| KAFKA
    REPLAY -->|"Replay NDJSON"| KAFKA
    KAFKA --> TOPIC1
    TOPIC1 -->|"Consume"| FE
    FE -->|"Publish"| TOPIC2
    TOPIC2 --> FAST
    FAST --> MODEL
    FAST --> BASE
    FAST -->|"/metrics"| PROM
    MODEL -->|"Track"| MLFLOW
    PROM --> GRAF
```

### Detailed Component Diagram

```mermaid
flowchart LR
    subgraph Client["ğŸ‘¤ Client"]
        REQ["HTTP Request"]
    end
    
    subgraph API["FastAPI Service (Port 8000)"]
        direction TB
        HEALTH["/health"]
        PREDICT["/predict"]
        VERSION["/version"]
        METRICS["/metrics"]
    end
    
    subgraph Models["Model Layer"]
        direction TB
        RF["Random Forest\n(MODEL_VARIANT=ml)"]
        BL["Baseline Z-Score\n(MODEL_VARIANT=baseline)"]
    end
    
    REQ --> HEALTH
    REQ --> PREDICT
    REQ --> VERSION
    REQ --> METRICS
    
    PREDICT --> RF
    PREDICT --> BL
```

### Data Flow Diagram

```mermaid
sequenceDiagram
    participant C as Coinbase WS
    participant I as Ingestor
    participant K as Kafka
    participant F as Featurizer
    participant A as API
    participant M as Model
    participant P as Prometheus
    
    Note over C,P: Live Mode
    C->>I: Ticker Data (JSON)
    I->>K: Publish to ticks.raw
    K->>F: Consume raw ticks
    F->>F: Compute features (30s, 60s, 300s windows)
    F->>K: Publish to ticks.features
    
    Note over C,P: Prediction Request
    A->>M: Load features
    M->>M: predict_proba()
    M->>A: Return scores
    A->>P: Record metrics
    
    Note over C,P: Replay Mode (Testing)
    Note right of I: Load NDJSON from disk
    I->>K: Replay historical data
```

### ASCII Architecture (for non-Mermaid viewers)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         DATA SOURCE                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚         Coinbase WebSocket API                           â”‚   â”‚
â”‚  â”‚    (wss://advanced-trade-ws.coinbase.com)               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      INGESTION LAYER                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚         Kafka Producer (scripts/ws_ingest.py)            â”‚   â”‚
â”‚  â”‚  â€¢ Subscribes to ticker channel                         â”‚   â”‚
â”‚  â”‚  â€¢ Publishes to Kafka topic: ticks.raw                  â”‚   â”‚
â”‚  â”‚  â€¢ Optional: Save to disk (NDJSON)                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MESSAGE BROKER (Kafka KRaft)                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚         Kafka Broker (Port: 9092)                        â”‚   â”‚
â”‚  â”‚  Topics:                                                 â”‚   â”‚
â”‚  â”‚  â€¢ ticks.raw      (raw ticker data)                     â”‚   â”‚
â”‚  â”‚  â€¢ ticks.features (computed features)                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FEATURE ENGINEERING                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚         Feature Pipeline (features/featurizer.py)       â”‚   â”‚
â”‚  â”‚  â€¢ Consumes from ticks.raw                              â”‚   â”‚
â”‚  â”‚  â€¢ Computes windowed features (30s, 60s, 300s)          â”‚   â”‚
â”‚  â”‚  â€¢ Publishes to ticks.features                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PREDICTION API (FastAPI)                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚         api/app.py (Port: 8000)                         â”‚   â”‚
â”‚  â”‚                                                          â”‚   â”‚
â”‚  â”‚  Endpoints:                                              â”‚   â”‚
â”‚  â”‚  â€¢ GET  /health    â†’ {"status": "healthy", ...}         â”‚   â”‚
â”‚  â”‚  â€¢ POST /predict   â†’ {"scores": [...], ...}             â”‚   â”‚
â”‚  â”‚  â€¢ GET  /version   â†’ {"model": "rf_v1", "sha": "..."}   â”‚   â”‚
â”‚  â”‚  â€¢ GET  /metrics   â†’ Prometheus format                  â”‚   â”‚
â”‚  â”‚                                                          â”‚   â”‚
â”‚  â”‚  Models:                                                 â”‚   â”‚
â”‚  â”‚  â€¢ Random Forest (MODEL_VARIANT=ml) - PR-AUC: 0.9859   â”‚   â”‚
â”‚  â”‚  â€¢ Baseline Z-Score (MODEL_VARIANT=baseline)            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MONITORING & TRACKING                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚    MLflow        â”‚  â”‚  Prometheus  â”‚  â”‚    Grafana      â”‚   â”‚
â”‚  â”‚    Port: 5001    â”‚  â”‚  Port: 9090  â”‚  â”‚    Port: 3000   â”‚   â”‚
â”‚  â”‚                  â”‚  â”‚              â”‚  â”‚                 â”‚   â”‚
â”‚  â”‚ â€¢ Model tracking â”‚  â”‚ â€¢ Latency    â”‚  â”‚ â€¢ Dashboards    â”‚   â”‚
â”‚  â”‚ â€¢ Experiments    â”‚  â”‚ â€¢ Requests   â”‚  â”‚ â€¢ Alerts        â”‚   â”‚
â”‚  â”‚ â€¢ Artifacts      â”‚  â”‚ â€¢ Errors     â”‚  â”‚ â€¢ SLOs          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Component Details

### 1. Ingestion Layer
- **Component**: `scripts/ws_ingest.py`
- **Function**: Connects to Coinbase WebSocket, streams ticker data
- **Output**: Kafka topic `ticks.raw`
- **Optional**: Saves raw data to `data/raw/*.ndjson`

### 2. Message Broker
- **Component**: Kafka (KRaft mode or Zookeeper mode)
- **Port**: 9092
- **Topics**:
  - `ticks.raw`: Raw ticker data from Coinbase
  - `ticks.features`: Computed features ready for prediction
- **Modes**: 
  - KRaft (no Zookeeper): `docker compose -f compose-kraft.yaml up -d`
  - Zookeeper: `docker compose up -d`

### 3. Feature Engineering
- **Component**: `features/featurizer.py`
- **Function**: 
  - Consumes from `ticks.raw`
  - Computes windowed features (30s, 60s, 300s windows)
  - Publishes to `ticks.features`
  - Saves to parquet for batch processing
- **Features**: 10 features including returns, volatility, spreads, trade intensity

### 4. Prediction API
- **Component**: `api/app.py` (FastAPI)
- **Port**: 8000
- **Endpoints**:
  - `GET /health`: Service health check
  - `POST /predict`: Make predictions (Assignment API)
  - `GET /version`: API and model version info
  - `GET /metrics`: Prometheus metrics
- **Model**: Random Forest - PR-AUC 0.9859
- **Rollback**: `MODEL_VARIANT=baseline` for z-score fallback

### 5. Monitoring & Tracking
- **MLflow** (Port 5001): Model versioning, experiment tracking
- **Prometheus** (Port 9090): Metrics collection via `/metrics` endpoint
- **Grafana** (Port 3000): Dashboards and alerting

---

## API Contract

### POST /predict
```json
// Request
{"rows": [{"ret_mean": 0.05, "ret_std": 0.01, "n": 50}]}

// Response
{"scores": [0.74], "model_variant": "ml", "version": "v1.2", "ts": "2025-11-02T14:33:00Z"}
```

### GET /health
```json
{"status": "healthy", "timestamp": "2025-11-25T10:30:00Z", "model_loaded": true, "kafka_connected": true}
```

### GET /version
```json
{"model": "random_forest_v1", "sha": "abc123", "version": "v1.2", "model_variant": "ml"}
```

---

## Data Flow

### Live Mode
1. **Coinbase WS** â†’ Ticker data â†’ **Ingestor** â†’ Kafka `ticks.raw`
2. **Feature Pipeline** â†’ Consume raw â†’ Compute features â†’ `ticks.features`
3. **API** â†’ Receive request â†’ Load model â†’ Predict â†’ Return scores
4. **Monitoring** â†’ Record latency/counts â†’ Prometheus â†’ Grafana

### Replay Mode (Testing)
1. **NDJSON file** â†’ `replay_to_kafka.py` â†’ Kafka `ticks.raw`
2. Same flow as live mode from step 2

---

## Deployment

### Quick Start (One Command)
```bash
cd docker && docker compose up -d
```

### Services Started
| Service | Container | Port | Purpose |
|---------|-----------|------|---------|
| Kafka | kafka | 9092 | Message broker |
| Zookeeper | zookeeper | 2182 | Kafka coordination |
| MLflow | mlflow-server | 5001 | Experiment tracking |
| API | volatility-api | 8000 | Prediction service |
| Prometheus | prometheus | 9090 | Metrics collection |
| Grafana | grafana | 3000 | Dashboards |

### Model Rollback
```bash
# Switch to ML model (default)
MODEL_VARIANT=ml docker compose up -d api

# Switch to baseline (rollback)
MODEL_VARIANT=baseline docker compose up -d api
```

---

## File Structure

```
â”œâ”€â”€ api/app.py              # FastAPI prediction service
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ compose.yaml        # Main Docker Compose (Zookeeper mode)
â”‚   â”œâ”€â”€ compose-kraft.yaml  # Alternative (KRaft mode)
â”‚   â”œâ”€â”€ Dockerfile.api      # API container
â”‚   â””â”€â”€ grafana/            # Grafana dashboards
â”œâ”€â”€ features/featurizer.py  # Feature engineering
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ artifacts/          # Trained models
â”‚   â”œâ”€â”€ train.py            # Training pipeline
â”‚   â””â”€â”€ infer.py            # Inference logic
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ ws_ingest.py        # WebSocket data ingestion
â”‚   â”œâ”€â”€ replay.py           # Offline replay
â”‚   â””â”€â”€ replay_to_kafka.py  # Replay to Kafka
â””â”€â”€ tests/                  # Integration tests
```

